# Model Provider Configuration

# Example 1: All Ollama (local)
ORCHESTRATOR_PROVIDER=ollama
ORCHESTRATOR_MODEL=llama3.2
ORCHESTRATOR_ENDPOINT=http://localhost:11434/v1

CYPHER_PROVIDER=ollama
CYPHER_MODEL=codellama
CYPHER_ENDPOINT=http://localhost:11434/v1

# Example 2: All OpenAI
# ORCHESTRATOR_PROVIDER=openai
# ORCHESTRATOR_MODEL=gpt-4o
# ORCHESTRATOR_API_KEY=sk-your-openai-key

# CYPHER_PROVIDER=openai
# CYPHER_MODEL=gpt-4o-mini
# CYPHER_API_KEY=sk-your-openai-key

# Example 3: All Google
# ORCHESTRATOR_PROVIDER=google
# ORCHESTRATOR_MODEL=gemini-2.5-pro
# ORCHESTRATOR_API_KEY=your-google-api-key

# CYPHER_PROVIDER=google
# CYPHER_MODEL=gemini-2.5-flash
# CYPHER_API_KEY=your-google-api-key

# Example 4: Mixed - Google orchestrator + Ollama cypher
# ORCHESTRATOR_PROVIDER=google
# ORCHESTRATOR_MODEL=gemini-2.5-pro
# ORCHESTRATOR_API_KEY=your-google-api-key

# CYPHER_PROVIDER=ollama
# CYPHER_MODEL=codellama
# CYPHER_ENDPOINT=http://localhost:11434/v1

# Example 5: Mixed - OpenAI orchestrator + Google cypher
# ORCHESTRATOR_PROVIDER=openai
# ORCHESTRATOR_MODEL=gpt-4o
# ORCHESTRATOR_API_KEY=sk-your-openai-key

# CYPHER_PROVIDER=google
# CYPHER_MODEL=gemini-2.5-flash
# CYPHER_API_KEY=your-google-api-key

# Memgraph settings
MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_HTTP_PORT=7444
LAB_PORT=3000
TARGET_REPO_PATH=.

EMBEDDING_BACKEND=OLLAMA
EMBEDDING_ENDPOINT=http://192.168.0.225:11434
EMBEDDING_MODEL=bge-m3:latest


QDRANT_TIMEOUT=60
QDRANT_PREFER_GRPC=true
QDRANT_RESUME_STATE=.tmp/qdrant_resume.json
QDRANT_BATCH=64         # 如果還會 timeout，試 32 或 16
QDRANT_MAX_LINES_PER_CHUNK=300